:experimental:
ifdef::env-github[]
:icons:
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]

= Amalgam(ation)

[TIP]
====
AVX2 may be faster than SSE2 though not all CPUs support it (`Steam > Help > System Information > Processor Information > AVX2`). Freetype uses freetype as the text rasterizer and includes some custom fonts, which results in better looking text but larger DLL sizes. PDBs are for developer use.
====

WARNING: This fork of Amalgam uses AI heavily, it's primarily as a testbed for it.

Only link:https://github.com/DarthTon/Xenos/releases[Xenos] and "protecting" both Xenos and Amalgamation with Themida is recommended, don't use a VAC bypass as you'll get banned after too many reports.

== Building

. Ensure Visual Studio 2022 is installed with "Desktop development with C++".
. Change to ReleaseFreetype if your CPU doesn't have AVX2: +
`.\Build.ps1 -ProjectPath "Amalgam.sln" -Configuration "ReleaseFreetypeAVX2" -Platform "x64"`
- Alternatively you can use Visual Studio 2022 to compile.

== AI

.Is it ready to improve pre-existing code yet?
- You can extract a few things out of it, but without effort, no.

.Is it expensive?
- Very, it's usually over $2 USD a file for one run, sometimes $3.

.Specifications
- AI model: Claude Sonnet 4 by Anthropic; used via API tokens on a tier 3 plan.
- AI coding agent: Roo Code; its Power Steering option is enabled for better prompt adherence.
- Editor or IDE: Visual Studio Code. Visual Studio is used exclusively for PVS-Studio and adding or removing files.
- Default prompt:
----
You must cache read every .cpp and .h file in bulk for the current codebase.
Use context7 mcp to lookup the following: /microsoftdocs/cpp-docs, /isocpp/cppcoreguidelines, and /valvesoftware/source-sdk-2013. The codebase language standard is C++23.
Always use the newest C++ language features if it's more performant.
Only add documentation if it helps in reading the code.
Do not create new files.
Apply the changes in small chunks at a time.
Aggressively introduce mathematical theories including numerical analysis, computational geometry, linear algebra optimizations, differential equations solvers, quaternion mathematics, vector field theory, physics simulation algorithms, spatial partitioning techniques, interpolation methods, optimization algorithms, statistical methods, signal processing techniques, and any other mathematical frameworks that would enhance the pre-existing code and implement comprehensive performance improvements including SIMD vectorization, cache-friendly data structures, memory pool allocation, branch prediction optimization, loop unrolling, template metaprogramming, constexpr evaluation, move semantics, perfect forwarding, and modern C++23 features.
Do not override the old comments or documentation.
Never create dummy or placeholder code.
Never check for errors or mistakes until after the build command is ran.

The build command for testing if changes were successful is: .\Build.ps1 -ProjectPath "Amalgam.sln" -Configuration "ReleaseFreetypeAVX2" -Platform "x64".

The file to apply changes is:
----

.Notes
- The code can be overcomplex if the AI is not told explicitly to keep it as simple as possible, however telling it initially to be as simple as possible results in a worse output. So it's better to let it go wild at first, then refine it later, despite this costing more $.
- AI sometimes generates broken code and requires manual fixing if not told to keep to the original vision as closely as possible, but doing this results in a worse output.
- The AI tasks have to be applied in small chunks at a time.
- AI can prototype if prompted correctly, but you have to manually fix its output.
- Original comments / documentation are overwritten unless specified not to do so.
- AI inserting `\[[unlikely]]` or `\[[likely]]` attributes into the code increases the chance of bugs, but is still good to experiment with.
- Context7 MCP isn't as good as fine tuning using the RAG (Retrieve Augment Generate) technique, it may be worth pursuing training a local AI with this approach for the Source SDK 2013 source code.
- If it improves code, it usually won't improve the underlying logic, therefore making no noticeable difference.


